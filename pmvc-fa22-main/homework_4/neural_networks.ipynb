{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "In this notebook, you will classify handwritten digits from the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using (i) a softmax regression model (as a baseline) and (ii) a convolutional neural network.\n",
    "\n",
    "Author(s): Raj Magesh Gauthaman (rgautha1@jh.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line and run this cell if you're using Google Colab\n",
    "\n",
    "# !pip install torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as tr\n",
    "from torchdata.datapipes.map import SequenceWrapper\n",
    "from torchdata.datapipes.iter import IterDataPipe\n",
    "\n",
    "\n",
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=28 * 28, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=1024, out_features=1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "def create_datapipe(train: bool, batch_size: int, buffer_size: int = 10000) -> tuple[IterDataPipe, IterDataPipe]:\n",
    "    datapipe = (\n",
    "        SequenceWrapper(MNIST(root=\"mnist\", train=train, download=True))\n",
    "        .to_iter_datapipe()\n",
    "    )\n",
    "    if buffer_size is not None:\n",
    "        datapipe = datapipe.cycle().shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    images, labels = datapipe.unzip(sequence_length=2)\n",
    "    images = (\n",
    "        images\n",
    "        .map(lambda image: tr.ToTensor()(image))\n",
    "        .batch(batch_size=batch_size)\n",
    "    )\n",
    "    labels = labels.batch(batch_size=batch_size)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = NeuralNetwork().to(device)\n",
    "# model = SoftmaxRegression().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_function = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "n_batches = 1000\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe_train = create_datapipe(train=True, batch_size=batch_size)\n",
    "\n",
    "model.train()\n",
    "\n",
    "batch = 0\n",
    "for images, labels in tqdm(zip(*datapipe_train), desc=\"batch\", leave=False):\n",
    "    images = torch.stack(images).to(device=device)\n",
    "    labels = torch.Tensor(labels).to(dtype=torch.long, device=device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    predicted_labels = model(images)\n",
    "    loss = loss_function(predicted_labels, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    batch += 1\n",
    "    if batch == n_batches:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapipe_test = create_datapipe(train=False, batch_size=batch_size, buffer_size=None)\n",
    "\n",
    "model.eval()\n",
    "correct_predictions = 0\n",
    "total = 0\n",
    "for images, labels in tqdm(zip(*datapipe_test), desc=\"batch\", leave=False):\n",
    "    images = torch.stack(images).to(device=device)\n",
    "    labels = torch.Tensor(labels).to(dtype=torch.long, device=device)\n",
    "\n",
    "    predicted_labels = model(images)\n",
    "    correct_predictions += (predicted_labels.argmax(dim=-1) == labels).sum()\n",
    "    total += len(predicted_labels)\n",
    "\n",
    "accuracy = correct_predictions / total\n",
    "print(f\"accuracy = {accuracy:.03}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "1. What do you expect the accuracy of an untrained model to be on the MNIST dataset? Why? Try evaluating an untrained model. What is the accuracy you obtain? (3 points)\n",
    "2. What is the loss function used here? Describe it. Why is it appropriate for a classification task? (4 points)\n",
    "3. Try using a neural network with only one convolutional layer (the `NeuralNetwork` class provided has two: remove the second one!) You will have to adjust the number of input features to your first linear layer. Do you find a accuracy difference between one-layer convolutional network and a two-layer convolutional network? Explain why/why not. (6 points)\n",
    "4. Try using the simple softmax regression model. Compare the results to those from the convolutional neural network. (2 points)\n",
    "5. Try changing the number of training batches for the softmax regression model (try 10, 100, 1000, and 10,000). How does the accuracy change? (5 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neural-dimensionality')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aca399878df662d12a33c13450d8b5abb2859ca28936f41d8414d834a053a1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
